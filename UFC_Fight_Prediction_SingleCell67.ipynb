{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "odKadF_aOmF7",
        "outputId": "53fee1aa-3bb9-451b-f384-e0d52bc9bda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLibraries imported!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/04 21:19:07 INFO mlflow.tracking.fluent: Experiment with name '/Users/anazaruk@asu.edu/UFC_Fight_Probability_Prediction' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: /Users/anazaruk@asu.edu/UFC_Fight_Probability_Prediction\n",
            "Please upload ufc_fights_2019_2025_with_stats.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6436164-0878-4bce-ba28-e1f8e277cdfc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c6436164-0878-4bce-ba28-e1f8e277cdfc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ufc_fights_2019_2025_with_stats.csv to ufc_fights_2019_2025_with_stats.csv\n",
            "Dataset: 7396 rows, 93 cols | Target balance: 50.00% Fighter A wins\n",
            "Features: 72 numerical, 6 categorical\n",
            "Train: 5916, Test: 1480\n",
            "\n",
            "============================================================\n",
            "1) DECISION TREE (4 runs)\n",
            "============================================================\n",
            "  DT_d5_gini: Acc=0.6243, F1=0.6160, AUC=0.6697, Brier=0.2289\n",
            "ğŸƒ View run DT_d5_gini at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/750d0d591c60451f859a11ca760399c7\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  DT_d5_entropy: Acc=0.6203, F1=0.6151, AUC=0.6659, Brier=0.2300\n",
            "ğŸƒ View run DT_d5_entropy at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/ca003644b2a3400794b0c777b2c16275\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  DT_d15_gini: Acc=0.5723, F1=0.5714, AUC=0.5587, Brier=0.3971\n",
            "ğŸƒ View run DT_d15_gini at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/a800cc0a8a554ea78610fbe2abf74816\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  DT_d15_entropy: Acc=0.5595, F1=0.5642, AUC=0.5838, Brier=0.3747\n",
            "ğŸƒ View run DT_d15_entropy at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/43bb2398627a40f2b86e8f18ec6ca8ca\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "2) LOGISTIC REGRESSION (4 runs)\n",
            "============================================================\n",
            "  LR_C0.1_l1: Acc=0.6514, F1=0.6509, AUC=0.7138, Brier=0.2157\n",
            "ğŸƒ View run LR_C0.1_l1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/f1d5bb2e893b4558a6d4cfab4a540187\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_C0.1_l2: Acc=0.6608, F1=0.6613, AUC=0.7093, Brier=0.2171\n",
            "ğŸƒ View run LR_C0.1_l2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/c44ac5c74bb842ef9a20b0f90c656429\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_C1.0_l1: Acc=0.6547, F1=0.6554, AUC=0.7039, Brier=0.2196\n",
            "ğŸƒ View run LR_C1.0_l1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/3f2d27bacf20442b936f85d913c3bfc8\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_C1.0_l2: Acc=0.6486, F1=0.6496, AUC=0.7004, Brier=0.2209\n",
            "ğŸƒ View run LR_C1.0_l2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/bbaf628e32d04d4c97b77b59d428eb12\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "3) SUPPORT VECTOR MACHINE (4 runs)\n",
            "============================================================\n",
            "  SVM_linear_C0.1: Acc=0.6595, F1=0.6617, AUC=0.7075, Brier=0.2179\n",
            "ğŸƒ View run SVM_linear_C0.1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/d585abd98cea4568ac267ef634a033da\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  SVM_linear_C1.0: Acc=0.6453, F1=0.6512, AUC=0.6918, Brier=0.2227\n",
            "ğŸƒ View run SVM_linear_C1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/b9f5d1d5244445dd95b2262e3c9e45ce\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  SVM_rbf_C0.1: Acc=0.6277, F1=0.6290, AUC=0.6840, Brier=0.2247\n",
            "ğŸƒ View run SVM_rbf_C0.1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/852c65d072714567817c07a3c095cc83\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  SVM_rbf_C1.0: Acc=0.6527, F1=0.6578, AUC=0.7001, Brier=0.2200\n",
            "ğŸƒ View run SVM_rbf_C1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/424fb0db62bb468398032900bed6e3a8\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "4) NEURAL NETWORK (6 runs)\n",
            "============================================================\n",
            "  NN_h(64,)_lr0.001: Acc=0.6365, F1=0.6300, AUC=0.6897, Brier=0.2238\n",
            "ğŸƒ View run NN_h(64,)_lr0.001 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/62befbf368e24b629ebeac3b6ed4bdba\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  NN_h(64,)_lr0.01: Acc=0.6365, F1=0.6446, AUC=0.6862, Brier=0.2265\n",
            "ğŸƒ View run NN_h(64,)_lr0.01 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/d7ccc31732d04cccbb56614edb5e81bc\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  NN_h(128,)_lr0.001: Acc=0.6514, F1=0.6514, AUC=0.6998, Brier=0.2203\n",
            "ğŸƒ View run NN_h(128,)_lr0.001 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/bd69438fc9374576a074d41c23499257\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  NN_h(128,)_lr0.01: Acc=0.6311, F1=0.6604, AUC=0.6961, Brier=0.2226\n",
            "ğŸƒ View run NN_h(128,)_lr0.01 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/2345e7b7c32a4388b79c6073722582c3\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  NN_h(64, 32)_lr0.001: Acc=0.6236, F1=0.6249, AUC=0.6676, Brier=0.2438\n",
            "ğŸƒ View run NN_h(64, 32)_lr0.001 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/01a9b89c181e4319a744d77e82c33895\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  NN_h(64, 32)_lr0.01: Acc=0.6149, F1=0.6365, AUC=0.6686, Brier=0.2357\n",
            "ğŸƒ View run NN_h(64, 32)_lr0.01 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/0d1f556ac5ec4d82a4f5dc1520ee0225\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "5) NAIVE BAYES (2 runs)\n",
            "============================================================\n",
            "  NB_vs1e-09: Acc=0.5189, F1=0.3074, AUC=0.5929, Brier=0.4765\n",
            "ğŸƒ View run NB_vs1e-09 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/79b383588d2e4796bff741dea46a35e4\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  NB_vs1e-07: Acc=0.5412, F1=0.3822, AUC=0.5924, Brier=0.4518\n",
            "ğŸƒ View run NB_vs1e-07 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/6259f303f4324b44b746b0ad459b21e2\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "6) RANDOM FOREST (8 runs)\n",
            "============================================================\n",
            "  RF_n100_d10_s2: Acc=0.6459, F1=0.6469, AUC=0.6957, Brier=0.2230\n",
            "ğŸƒ View run RF_n100_d10_s2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/f2149bbf33d44479859230cb15c82eb7\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  RF_n100_d10_s5: Acc=0.6419, F1=0.6452, AUC=0.6895, Brier=0.2246\n",
            "ğŸƒ View run RF_n100_d10_s5 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/c8c7ced223e540f5b7db01e339bd86a1\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  RF_n100_d20_s2: Acc=0.6500, F1=0.6514, AUC=0.6952, Brier=0.2219\n",
            "ğŸƒ View run RF_n100_d20_s2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/6909c2341c3d4843bd2829584469c834\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  RF_n100_d20_s5: Acc=0.6351, F1=0.6366, AUC=0.6900, Brier=0.2233\n",
            "ğŸƒ View run RF_n100_d20_s5 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/33ef9e2659e8463eb8faad6a38699484\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  RF_n200_d10_s2: Acc=0.6500, F1=0.6514, AUC=0.6945, Brier=0.2233\n",
            "ğŸƒ View run RF_n200_d10_s2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/38000bf436db4c30af308a95efe494e6\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  RF_n200_d10_s5: Acc=0.6432, F1=0.6442, AUC=0.6931, Brier=0.2239\n",
            "ğŸƒ View run RF_n200_d10_s5 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/4f7a7a2ae7944cc2952a2db3fd915380\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  RF_n200_d20_s2: Acc=0.6412, F1=0.6467, AUC=0.6961, Brier=0.2221\n",
            "ğŸƒ View run RF_n200_d20_s2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/11946b9096214ceea7ea413dfdc4ba23\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  RF_n200_d20_s5: Acc=0.6466, F1=0.6511, AUC=0.6939, Brier=0.2227\n",
            "ğŸƒ View run RF_n200_d20_s5 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/50e5cacdb8a1424190d6c8e54f650931\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "7) XGBOOST (8 runs)\n",
            "============================================================\n",
            "  XGB_n100_lr0.05_d4: Acc=0.6581, F1=0.6604, AUC=0.7157, Brier=0.2158\n",
            "ğŸƒ View run XGB_n100_lr0.05_d4 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/fc6f7a7543ad4c4f8fe451285421454b\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_n100_lr0.05_d8: Acc=0.6426, F1=0.6438, AUC=0.7023, Brier=0.2202\n",
            "ğŸƒ View run XGB_n100_lr0.05_d8 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/be66cd117c6b4751b55a2d1e3bd3aa8c\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_n100_lr0.1_d4: Acc=0.6635, F1=0.6671, AUC=0.7168, Brier=0.2152\n",
            "ğŸƒ View run XGB_n100_lr0.1_d4 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/81a85f53ea6c4a2d9ab3e9286c2330cf\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_n100_lr0.1_d8: Acc=0.6473, F1=0.6501, AUC=0.7023, Brier=0.2223\n",
            "ğŸƒ View run XGB_n100_lr0.1_d8 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/379736919b5d476fb6a75cfb1866ec42\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_n200_lr0.05_d4: Acc=0.6568, F1=0.6558, AUC=0.7142, Brier=0.2160\n",
            "ğŸƒ View run XGB_n200_lr0.05_d4 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/8df3f662f7a5443e9ef72b25ebc49947\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_n200_lr0.05_d8: Acc=0.6331, F1=0.6348, AUC=0.6986, Brier=0.2234\n",
            "ğŸƒ View run XGB_n200_lr0.05_d8 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/c9c66a4a3a1145aebda20be68eeaca44\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_n200_lr0.1_d4: Acc=0.6588, F1=0.6613, AUC=0.7064, Brier=0.2193\n",
            "ğŸƒ View run XGB_n200_lr0.1_d4 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/3d89d0a1f31e422ea64ab4b2b7284bb2\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_n200_lr0.1_d8: Acc=0.6345, F1=0.6386, AUC=0.6909, Brier=0.2331\n",
            "ğŸƒ View run XGB_n200_lr0.1_d8 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/45eee5e4b37b418d915e117d92bad629\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "8) K-NEAREST NEIGHBORS (8 runs)\n",
            "============================================================\n",
            "  KNN_k5_uniform_euclidean: Acc=0.5777, F1=0.5763, AUC=0.5902, Brier=0.2725\n",
            "ğŸƒ View run KNN_k5_uniform_euclidean at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/025e22aafd5744679dbf3169a5cae768\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  KNN_k5_uniform_manhattan: Acc=0.5730, F1=0.5770, AUC=0.5896, Brier=0.2726\n",
            "ğŸƒ View run KNN_k5_uniform_manhattan at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/2bc1e79cba234dc3954ef2aaad74fe69\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  KNN_k5_distance_euclidean: Acc=0.5784, F1=0.5772, AUC=0.5887, Brier=0.2731\n",
            "ğŸƒ View run KNN_k5_distance_euclidean at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/417f7609fbaa4ae2a2e04102ffb190e2\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  KNN_k5_distance_manhattan: Acc=0.5736, F1=0.5779, AUC=0.5942, Brier=0.2726\n",
            "ğŸƒ View run KNN_k5_distance_manhattan at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/46363b22c1274d3abca81f84dbcca3aa\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  KNN_k11_uniform_euclidean: Acc=0.5973, F1=0.6011, AUC=0.6355, Brier=0.2418\n",
            "ğŸƒ View run KNN_k11_uniform_euclidean at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/eb26c31a46ab49fcbebb76b945fbcdc8\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  KNN_k11_uniform_manhattan: Acc=0.5892, F1=0.5925, AUC=0.6295, Brier=0.2437\n",
            "ğŸƒ View run KNN_k11_uniform_manhattan at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/3b2e329427c7420ab7218aa06318faff\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  KNN_k11_distance_euclidean: Acc=0.5980, F1=0.6009, AUC=0.6319, Brier=0.2425\n",
            "ğŸƒ View run KNN_k11_distance_euclidean at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/77f48e0e6a324f6eb2bd5516e5c02efd\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  KNN_k11_distance_manhattan: Acc=0.5919, F1=0.5941, AUC=0.6310, Brier=0.2438\n",
            "ğŸƒ View run KNN_k11_distance_manhattan at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/e6806de215aa4fe6bd8a3daf2d5aa780\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "9a) ENSEMBLE - VOTING CLASSIFIER (1 run)\n",
            "============================================================\n",
            "  Ensemble_Voting: Acc=0.6466, F1=0.6473, AUC=0.7077, Brier=0.2175\n",
            "ğŸƒ View run Ensemble_Voting at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/b10f08fcd52f4814adbdd97591dab997\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "9b) ENSEMBLE - STACKING CLASSIFIER (1 run)\n",
            "============================================================\n",
            "  Ensemble_Stacking: Acc=0.6426, F1=0.6452, AUC=0.7059, Brier=0.2184\n",
            "ğŸƒ View run Ensemble_Stacking at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/e53a2eb2f97545a2a415f8e788b43d82\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "============================================================\n",
            "FINAL SUMMARY\n",
            "============================================================\n",
            "\n",
            "TOTAL RUNS: 46\n",
            "\n",
            "Runs by Model Type:\n",
            "  Decision Tree: 4, Logistic Regression: 4, SVM: 4\n",
            "  Neural Network: 6, Naive Bayes: 2, Random Forest: 8\n",
            "  XGBoost: 8, KNN: 8, Ensemble: 2\n",
            "\n",
            "Top 10 Models by ROC-AUC:\n",
            "          run_name         model_type       f1  roc_auc\n",
            " XGB_n100_lr0.1_d4            XGBoost 0.667112 0.716766\n",
            "XGB_n100_lr0.05_d4            XGBoost 0.660403 0.715681\n",
            "XGB_n200_lr0.05_d4            XGBoost 0.655827 0.714180\n",
            "        LR_C0.1_l1 LogisticRegression 0.650880 0.713811\n",
            "        LR_C0.1_l2 LogisticRegression 0.661269 0.709339\n",
            "   Ensemble_Voting           Ensemble 0.647336 0.707715\n",
            "   SVM_linear_C0.1                SVM 0.661745 0.707515\n",
            " XGB_n200_lr0.1_d4            XGBoost 0.661301 0.706395\n",
            " Ensemble_Stacking           Ensemble 0.645205 0.705950\n",
            "        LR_C1.0_l1 LogisticRegression 0.655428 0.703870\n",
            "\n",
            "ğŸ† BEST MODEL: XGB_n100_lr0.1_d4 (XGBoost) | F1=0.6671 | AUC=0.7168\n",
            "\n",
            "âœ… All 46 runs logged to Databricks MLflow: /Users/anazaruk@asu.edu/UFC_Fight_Probability_Prediction\n",
            "\n",
            "âœ… Best model saved as: ufc_fight_predictor.pkl\n",
            "\n",
            "============================================================\n",
            "SAMPLE PREDICTION\n",
            "============================================================\n",
            "Sample fight prediction:\n",
            "  P(Fighter A Wins): 60.94%\n",
            "  P(Fighter B Wins): 39.06%\n",
            "  Actual outcome: Fighter A Won\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================================\n",
        "# UFC FIGHT OUTCOME PROBABILITY PREDICTION - FINAL PROJECT (SINGLE CELL)\n",
        "# CIS 508 Machine Learning in Business\n",
        "# Author: Anthony Nazaruk\n",
        "# Objective: Predict P(Fighter A Wins) - probability between 0 and 1\n",
        "# Models: Decision Tree, Logistic Regression, SVM, Neural Network, Naive Bayes,\n",
        "#         Random Forest, XGBoost, KNN, Ensemble (Voting & Stacking)\n",
        "# ===================================================================================\n",
        "\n",
        "!pip install mlflow xgboost -q\n",
        "\n",
        "import os, mlflow, mlflow.sklearn, pandas as pd, numpy as np, matplotlib.pyplot as plt, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc, brier_score_loss)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "print(\"Libraries imported!\")\n",
        "\n",
        "# --- DATABRICKS MLFLOW CONFIG ---\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"DATABRICKS_HOST\"] = userdata.get(\"DATABRICKS_HOST\")\n",
        "    os.environ[\"DATABRICKS_TOKEN\"] = userdata.get(\"DATABRICKS_TOKEN\")\n",
        "except: print(\"Configure Databricks secrets manually if needed.\")\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "experiment_name = \"/Users/anazaruk@asu.edu/UFC_Fight_Probability_Prediction\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "print(f\"Experiment: {experiment_name}\")\n",
        "\n",
        "# --- LOAD DATASET ---\n",
        "CSV_FILE = \"ufc_fights_2019_2025_with_stats.csv\"\n",
        "TARGET = \"fighter_a_won\"\n",
        "if not os.path.exists(CSV_FILE):\n",
        "    from google.colab import files\n",
        "    print(f\"Please upload {CSV_FILE}\"); uploaded = files.upload()\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "print(f\"Dataset: {df.shape[0]} rows, {df.shape[1]} cols | Target balance: {df[TARGET].mean():.2%} Fighter A wins\")\n",
        "\n",
        "# --- DATA PREPROCESSING ---\n",
        "cols_to_drop = ['fight_key', 'fight_id', 'event_id', 'event_date', 'event_name', 'promotion',\n",
        "                'fighter_a_id', 'fighter_a_name', 'fighter_b_id', 'fighter_b_name',\n",
        "                'title_fight', 'fight_end_round', 'fight_result_type', 'fight_duration']\n",
        "cols_to_drop = [c for c in cols_to_drop if c in df.columns]\n",
        "df_model = df.drop(columns=cols_to_drop).copy()\n",
        "cat_cols = [c for c in df_model.columns if c != TARGET and df_model[c].dtype == 'object']\n",
        "num_cols = [c for c in df_model.columns if c != TARGET and df_model[c].dtype != 'object']\n",
        "y = df_model[TARGET].copy()\n",
        "X = df_model.drop(columns=[TARGET]).copy()\n",
        "for col in cat_cols: X[col] = X[col].fillna('Unknown')\n",
        "for col in num_cols: X[col] = X[col].fillna(X[col].median())\n",
        "# *** FIX: Replace infinity and clip extreme values ***\n",
        "X = X.replace([np.inf, -np.inf], np.nan)\n",
        "for col in num_cols:\n",
        "    X[col] = X[col].fillna(X[col].median())\n",
        "    X[col] = X[col].clip(lower=-1e9, upper=1e9)\n",
        "print(f\"Features: {len(num_cols)} numerical, {len(cat_cols)} categorical\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Train: {X_train.shape[0]}, Test: {X_test.shape[0]}\")\n",
        "\n",
        "# --- PREPROCESSING PIPELINES ---\n",
        "preprocess_tree = ColumnTransformer([(\"num\", \"passthrough\", num_cols), (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)])\n",
        "preprocess_scaled = ColumnTransformer([(\"num\", StandardScaler(), num_cols), (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols)])\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "def log_cm(cm, fname=\"cm.png\"):\n",
        "    fig, ax = plt.subplots(figsize=(4,4)); ax.imshow(cm, cmap=\"Blues\")\n",
        "    ax.set_xticks([0,1]); ax.set_xticklabels([\"Loss\",\"Win\"]); ax.set_yticks([0,1]); ax.set_yticklabels([\"Loss\",\"Win\"])\n",
        "    for (i,j),v in np.ndenumerate(cm): ax.text(j,i,str(v),ha=\"center\",va=\"center\",fontsize=12)\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\"); plt.tight_layout(); fig.savefig(fname); plt.close(fig); mlflow.log_artifact(fname)\n",
        "\n",
        "def log_curves(y_true, y_prob, prefix=\"\"):\n",
        "    fpr,tpr,_ = roc_curve(y_true,y_prob); fig,ax = plt.subplots(figsize=(4,4)); ax.plot(fpr,tpr); ax.plot([0,1],[0,1],'--',color='gray')\n",
        "    ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.set_title(f\"ROC AUC={auc(fpr,tpr):.3f}\"); plt.tight_layout(); fig.savefig(f\"{prefix}roc.png\"); plt.close(fig); mlflow.log_artifact(f\"{prefix}roc.png\")\n",
        "    prec,rec,_ = precision_recall_curve(y_true,y_prob); fig,ax = plt.subplots(figsize=(4,4)); ax.plot(rec,prec)\n",
        "    ax.set_xlabel(\"Recall\"); ax.set_ylabel(\"Precision\"); ax.set_title(f\"PR AUC={auc(rec,prec):.3f}\"); plt.tight_layout(); fig.savefig(f\"{prefix}pr.png\"); plt.close(fig); mlflow.log_artifact(f\"{prefix}pr.png\")\n",
        "\n",
        "def train_and_log(run_name, clf, preprocess, model_type, params):\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
        "        acc, prec, rec = accuracy_score(y_test,y_pred), precision_score(y_test,y_pred,zero_division=0), recall_score(y_test,y_pred,zero_division=0)\n",
        "        f1, rocauc, brier = f1_score(y_test,y_pred,zero_division=0), roc_auc_score(y_test,y_prob), brier_score_loss(y_test,y_prob)\n",
        "        mlflow.log_metric(\"test_accuracy\",acc); mlflow.log_metric(\"test_precision\",prec); mlflow.log_metric(\"test_recall\",rec)\n",
        "        mlflow.log_metric(\"test_f1\",f1); mlflow.log_metric(\"roc_auc\",rocauc); mlflow.log_metric(\"brier_score\",brier)\n",
        "        mlflow.log_param(\"model_type\", model_type)\n",
        "        for k,v in params.items(): mlflow.log_param(k,v)\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=[0,1]); log_cm(cm, f\"{run_name}_cm.png\"); log_curves(y_test, y_prob, f\"{run_name}_\")\n",
        "        print(f\"  {run_name}: Acc={acc:.4f}, F1={f1:.4f}, AUC={rocauc:.4f}, Brier={brier:.4f}\")\n",
        "        return {\"run_name\": run_name, \"pipe\": pipe, \"f1\": f1, \"roc_auc\": rocauc, \"model_type\": model_type}\n",
        "\n",
        "mlflow.sklearn.autolog(log_models=True)\n",
        "all_runs = []\n",
        "\n",
        "# ===================================================================================\n",
        "# 1) DECISION TREE (4 runs): max_depth x criterion\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n1) DECISION TREE (4 runs)\\n\" + \"=\"*60)\n",
        "dt_runs = []\n",
        "for depth in [5, 15]:\n",
        "    for crit in [\"gini\", \"entropy\"]:\n",
        "        run = train_and_log(f\"DT_d{depth}_{crit}\", DecisionTreeClassifier(max_depth=depth, criterion=crit, random_state=42), preprocess_tree, \"DecisionTree\", {\"max_depth\":depth, \"criterion\":crit})\n",
        "        dt_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 2) LOGISTIC REGRESSION (4 runs): C x penalty\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n2) LOGISTIC REGRESSION (4 runs)\\n\" + \"=\"*60)\n",
        "lr_runs = []\n",
        "for C in [0.1, 1.0]:\n",
        "    for pen in [\"l1\", \"l2\"]:\n",
        "        run = train_and_log(f\"LR_C{C}_{pen}\", LogisticRegression(C=C, penalty=pen, solver=\"liblinear\", max_iter=1000, random_state=42), preprocess_scaled, \"LogisticRegression\", {\"C\":C, \"penalty\":pen})\n",
        "        lr_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 3) SVM (4 runs): kernel x C\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n3) SUPPORT VECTOR MACHINE (4 runs)\\n\" + \"=\"*60)\n",
        "svm_runs = []\n",
        "for kern in [\"linear\", \"rbf\"]:\n",
        "    for C in [0.1, 1.0]:\n",
        "        run = train_and_log(f\"SVM_{kern}_C{C}\", SVC(kernel=kern, C=C, probability=True, random_state=42), preprocess_scaled, \"SVM\", {\"kernel\":kern, \"C\":C})\n",
        "        svm_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 4) NEURAL NETWORK (6 runs): hidden_layers x learning_rate\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n4) NEURAL NETWORK (6 runs)\\n\" + \"=\"*60)\n",
        "nn_runs = []\n",
        "for hidden in [(64,), (128,), (64,32)]:\n",
        "    for lr in [0.001, 0.01]:\n",
        "        run = train_and_log(f\"NN_h{hidden}_lr{lr}\", MLPClassifier(hidden_layer_sizes=hidden, learning_rate_init=lr, max_iter=500, early_stopping=True, random_state=42), preprocess_scaled, \"NeuralNetwork\", {\"hidden_layers\":str(hidden), \"learning_rate\":lr})\n",
        "        nn_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 5) NAIVE BAYES (2 runs): var_smoothing\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n5) NAIVE BAYES (2 runs)\\n\" + \"=\"*60)\n",
        "nb_runs = []\n",
        "for vs in [1e-9, 1e-7]:\n",
        "    run = train_and_log(f\"NB_vs{vs}\", GaussianNB(var_smoothing=vs), preprocess_scaled, \"NaiveBayes\", {\"var_smoothing\":vs})\n",
        "    nb_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 6) RANDOM FOREST (8 runs): n_estimators x max_depth x min_samples_split\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n6) RANDOM FOREST (8 runs)\\n\" + \"=\"*60)\n",
        "rf_runs = []\n",
        "for n_est in [100, 200]:\n",
        "    for depth in [10, 20]:\n",
        "        for min_split in [2, 5]:\n",
        "            run = train_and_log(f\"RF_n{n_est}_d{depth}_s{min_split}\", RandomForestClassifier(n_estimators=n_est, max_depth=depth, min_samples_split=min_split, random_state=42, n_jobs=-1), preprocess_tree, \"RandomForest\", {\"n_estimators\":n_est, \"max_depth\":depth, \"min_samples_split\":min_split})\n",
        "            rf_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 7) XGBOOST (8 runs): n_estimators x learning_rate x max_depth\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n7) XGBOOST (8 runs)\\n\" + \"=\"*60)\n",
        "xgb_runs = []\n",
        "for n_est in [100, 200]:\n",
        "    for lr in [0.05, 0.1]:\n",
        "        for depth in [4, 8]:\n",
        "            run = train_and_log(f\"XGB_n{n_est}_lr{lr}_d{depth}\", XGBClassifier(n_estimators=n_est, learning_rate=lr, max_depth=depth, random_state=42, use_label_encoder=False, eval_metric='logloss', n_jobs=-1), preprocess_tree, \"XGBoost\", {\"n_estimators\":n_est, \"learning_rate\":lr, \"max_depth\":depth})\n",
        "            xgb_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 8) KNN (8 runs): n_neighbors x weights x metric\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n8) K-NEAREST NEIGHBORS (8 runs)\\n\" + \"=\"*60)\n",
        "knn_runs = []\n",
        "for k in [5, 11]:\n",
        "    for w in [\"uniform\", \"distance\"]:\n",
        "        for m in [\"euclidean\", \"manhattan\"]:\n",
        "            run = train_and_log(f\"KNN_k{k}_{w}_{m}\", KNeighborsClassifier(n_neighbors=k, weights=w, metric=m, n_jobs=-1), preprocess_scaled, \"KNN\", {\"n_neighbors\":k, \"weights\":w, \"metric\":m})\n",
        "            knn_runs.append(run); all_runs.append(run)\n",
        "\n",
        "# ===================================================================================\n",
        "# 9) ENSEMBLE - VOTING CLASSIFIER (1 run)\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n9a) ENSEMBLE - VOTING CLASSIFIER (1 run)\\n\" + \"=\"*60)\n",
        "with mlflow.start_run(run_name=\"Ensemble_Voting\"):\n",
        "    voting_clf = VotingClassifier(estimators=[\n",
        "        ('rf', RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)),\n",
        "        ('xgb', XGBClassifier(n_estimators=200, learning_rate=0.1, max_depth=8, random_state=42, use_label_encoder=False, eval_metric='logloss')),\n",
        "        ('lr', LogisticRegression(C=1.0, penalty='l2', solver='liblinear', max_iter=1000, random_state=42)),\n",
        "    ], voting='soft')\n",
        "    pipe_vote = Pipeline([(\"prep\", preprocess_scaled), (\"clf\", voting_clf)])\n",
        "    pipe_vote.fit(X_train, y_train)\n",
        "    y_pred_v = pipe_vote.predict(X_test); y_prob_v = pipe_vote.predict_proba(X_test)[:,1]\n",
        "    acc_v, f1_v, auc_v, brier_v = accuracy_score(y_test,y_pred_v), f1_score(y_test,y_pred_v), roc_auc_score(y_test,y_prob_v), brier_score_loss(y_test,y_prob_v)\n",
        "    mlflow.log_metric(\"test_accuracy\",acc_v); mlflow.log_metric(\"test_f1\",f1_v); mlflow.log_metric(\"roc_auc\",auc_v); mlflow.log_metric(\"brier_score\",brier_v)\n",
        "    mlflow.log_param(\"model_type\",\"VotingEnsemble\"); mlflow.log_param(\"base_models\",\"RF,XGB,LR\")\n",
        "    cm_v = confusion_matrix(y_test,y_pred_v,labels=[0,1]); log_cm(cm_v,\"Ensemble_Voting_cm.png\"); log_curves(y_test,y_prob_v,\"Ensemble_Voting_\")\n",
        "    print(f\"  Ensemble_Voting: Acc={acc_v:.4f}, F1={f1_v:.4f}, AUC={auc_v:.4f}, Brier={brier_v:.4f}\")\n",
        "    all_runs.append({\"run_name\":\"Ensemble_Voting\", \"pipe\":pipe_vote, \"f1\":f1_v, \"roc_auc\":auc_v, \"model_type\":\"Ensemble\"})\n",
        "\n",
        "# ===================================================================================\n",
        "# 9) ENSEMBLE - STACKING CLASSIFIER (1 run)\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n9b) ENSEMBLE - STACKING CLASSIFIER (1 run)\\n\" + \"=\"*60)\n",
        "with mlflow.start_run(run_name=\"Ensemble_Stacking\"):\n",
        "    stacking_clf = StackingClassifier(estimators=[\n",
        "        ('rf', RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)),\n",
        "        ('xgb', XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=8, random_state=42, use_label_encoder=False, eval_metric='logloss')),\n",
        "        ('knn', KNeighborsClassifier(n_neighbors=11, weights='distance', metric='euclidean')),\n",
        "    ], final_estimator=LogisticRegression(max_iter=1000, random_state=42), cv=5, n_jobs=-1)\n",
        "    pipe_stack = Pipeline([(\"prep\", preprocess_scaled), (\"clf\", stacking_clf)])\n",
        "    pipe_stack.fit(X_train, y_train)\n",
        "    y_pred_s = pipe_stack.predict(X_test); y_prob_s = pipe_stack.predict_proba(X_test)[:,1]\n",
        "    acc_s, f1_s, auc_s, brier_s = accuracy_score(y_test,y_pred_s), f1_score(y_test,y_pred_s), roc_auc_score(y_test,y_prob_s), brier_score_loss(y_test,y_prob_s)\n",
        "    mlflow.log_metric(\"test_accuracy\",acc_s); mlflow.log_metric(\"test_f1\",f1_s); mlflow.log_metric(\"roc_auc\",auc_s); mlflow.log_metric(\"brier_score\",brier_s)\n",
        "    mlflow.log_param(\"model_type\",\"StackingEnsemble\"); mlflow.log_param(\"base_models\",\"RF,XGB,KNN\"); mlflow.log_param(\"meta_learner\",\"LogisticRegression\")\n",
        "    cm_s = confusion_matrix(y_test,y_pred_s,labels=[0,1]); log_cm(cm_s,\"Ensemble_Stacking_cm.png\"); log_curves(y_test,y_prob_s,\"Ensemble_Stacking_\")\n",
        "    print(f\"  Ensemble_Stacking: Acc={acc_s:.4f}, F1={f1_s:.4f}, AUC={auc_s:.4f}, Brier={brier_s:.4f}\")\n",
        "    all_runs.append({\"run_name\":\"Ensemble_Stacking\", \"pipe\":pipe_stack, \"f1\":f1_s, \"roc_auc\":auc_s, \"model_type\":\"Ensemble\"})\n",
        "\n",
        "# ===================================================================================\n",
        "# FINAL SUMMARY\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "summary_df = pd.DataFrame(all_runs).sort_values(by=\"roc_auc\", ascending=False)\n",
        "print(f\"\\nTOTAL RUNS: {len(all_runs)}\")\n",
        "print(f\"\\nRuns by Model Type:\")\n",
        "print(f\"  Decision Tree: {len(dt_runs)}, Logistic Regression: {len(lr_runs)}, SVM: {len(svm_runs)}\")\n",
        "print(f\"  Neural Network: {len(nn_runs)}, Naive Bayes: {len(nb_runs)}, Random Forest: {len(rf_runs)}\")\n",
        "print(f\"  XGBoost: {len(xgb_runs)}, KNN: {len(knn_runs)}, Ensemble: 2\")\n",
        "print(f\"\\nTop 10 Models by ROC-AUC:\")\n",
        "print(summary_df[[\"run_name\", \"model_type\", \"f1\", \"roc_auc\"]].head(10).to_string(index=False))\n",
        "best = summary_df.iloc[0]\n",
        "print(f\"\\nğŸ† BEST MODEL: {best['run_name']} ({best['model_type']}) | F1={best['f1']:.4f} | AUC={best['roc_auc']:.4f}\")\n",
        "print(f\"\\nâœ… All {len(all_runs)} runs logged to Databricks MLflow: {experiment_name}\")\n",
        "\n",
        "# --- SAVE BEST MODEL ---\n",
        "import pickle\n",
        "best_pipe = best['pipe']\n",
        "with open('ufc_fight_predictor.pkl', 'wb') as f: pickle.dump(best_pipe, f)\n",
        "print(f\"\\nâœ… Best model saved as: ufc_fight_predictor.pkl\")\n",
        "\n",
        "# --- SAMPLE PREDICTION ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAMPLE PREDICTION\")\n",
        "print(\"=\"*60)\n",
        "sample = X_test.iloc[[0]]\n",
        "prob = best_pipe.predict_proba(sample)[0][1]\n",
        "print(f\"Sample fight prediction:\")\n",
        "print(f\"  P(Fighter A Wins): {prob:.2%}\")\n",
        "print(f\"  P(Fighter B Wins): {1-prob:.2%}\")\n",
        "print(f\"  Actual outcome: {'Fighter A Won' if y_test.iloc[0]==1 else 'Fighter B Won'}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================================================================\n",
        "# UFC FIGHT PREDICTION - HYPERPARAMETER FINE-TUNING (RUN AFTER INITIAL 46 RUNS)\n",
        "# Based on best performers: XGBoost (depth=4) and Logistic Regression (C=0.1)\n",
        "# This will add ~25 more fine-tuned runs\n",
        "# ===================================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"HYPERPARAMETER FINE-TUNING - PHASE 2\")\n",
        "print(\"Based on best initial results: XGBoost & Logistic Regression\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ===================================================================================\n",
        "# 1) XGBOOST FINE-TUNING (12 runs)\n",
        "# Best was: n_estimators=100, learning_rate=0.1, max_depth=4\n",
        "# Fine-tune around those values + add regularization params\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"1) XGBOOST FINE-TUNING (12 runs)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "xgb_tuned_runs = []\n",
        "\n",
        "# Fine-grained search around best params\n",
        "xgb_fine_grid = {\n",
        "    \"n_estimators\": [75, 100, 150],      # around 100\n",
        "    \"learning_rate\": [0.08, 0.1, 0.12],  # around 0.1\n",
        "    \"max_depth\": [3, 4, 5],              # around 4\n",
        "    \"reg_alpha\": [0, 0.1],               # L1 regularization\n",
        "    \"reg_lambda\": [1, 2],                # L2 regularization\n",
        "    \"subsample\": [0.8, 1.0],             # row sampling\n",
        "    \"colsample_bytree\": [0.8, 1.0],      # column sampling\n",
        "}\n",
        "\n",
        "# Run targeted combinations (not full grid - too many)\n",
        "xgb_configs = [\n",
        "    # Vary depth around best\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 3, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 5, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    # Vary n_estimators\n",
        "    {\"n_estimators\": 75, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    {\"n_estimators\": 150, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    # Vary learning rate\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.08, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.12, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    # Add L1 regularization\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0.1, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0.5, \"reg_lambda\": 1, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    # Add L2 regularization\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 2, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 5, \"subsample\": 1.0, \"colsample_bytree\": 1.0},\n",
        "    # Add subsampling (reduces overfitting)\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 0.8, \"colsample_bytree\": 1.0},\n",
        "    {\"n_estimators\": 100, \"learning_rate\": 0.1, \"max_depth\": 4, \"reg_alpha\": 0, \"reg_lambda\": 1, \"subsample\": 0.8, \"colsample_bytree\": 0.8},\n",
        "]\n",
        "\n",
        "for cfg in xgb_configs:\n",
        "    run_name = f\"XGB_TUNED_n{cfg['n_estimators']}_lr{cfg['learning_rate']}_d{cfg['max_depth']}_a{cfg['reg_alpha']}_l{cfg['reg_lambda']}_ss{cfg['subsample']}\"\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        clf = XGBClassifier(\n",
        "            n_estimators=cfg['n_estimators'],\n",
        "            learning_rate=cfg['learning_rate'],\n",
        "            max_depth=cfg['max_depth'],\n",
        "            reg_alpha=cfg['reg_alpha'],\n",
        "            reg_lambda=cfg['reg_lambda'],\n",
        "            subsample=cfg['subsample'],\n",
        "            colsample_bytree=cfg['colsample_bytree'],\n",
        "            random_state=42,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        pipe = Pipeline([(\"prep\", preprocess_tree), (\"clf\", clf)])\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "        rocauc = roc_auc_score(y_test, y_prob)\n",
        "        brier = brier_score_loss(y_test, y_prob)\n",
        "\n",
        "        mlflow.log_metric(\"test_accuracy\", acc)\n",
        "        mlflow.log_metric(\"test_precision\", prec)\n",
        "        mlflow.log_metric(\"test_recall\", rec)\n",
        "        mlflow.log_metric(\"test_f1\", f1)\n",
        "        mlflow.log_metric(\"roc_auc\", rocauc)\n",
        "        mlflow.log_metric(\"brier_score\", brier)\n",
        "        mlflow.log_param(\"model_type\", \"XGBoost_Tuned\")\n",
        "        for k, v in cfg.items():\n",
        "            mlflow.log_param(k, v)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "        log_cm(cm, f\"{run_name}_cm.png\")\n",
        "        log_curves(y_test, y_prob, f\"{run_name}_\")\n",
        "\n",
        "        xgb_tuned_runs.append({\"run_name\": run_name, \"pipe\": pipe, \"f1\": f1, \"roc_auc\": rocauc, \"brier\": brier, \"config\": cfg})\n",
        "        print(f\"  {run_name}: AUC={rocauc:.4f}, Acc={acc:.4f}, F1={f1:.4f}, Brier={brier:.4f}\")\n",
        "\n",
        "print(f\"\\nâœ… XGBoost Fine-Tuning: {len(xgb_tuned_runs)} runs completed\")\n",
        "\n",
        "# ===================================================================================\n",
        "# 2) LOGISTIC REGRESSION FINE-TUNING (8 runs)\n",
        "# Best was: C=0.1, penalty=l1\n",
        "# Fine-tune C values and try elastic net\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"2) LOGISTIC REGRESSION FINE-TUNING (8 runs)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "lr_tuned_runs = []\n",
        "\n",
        "lr_configs = [\n",
        "    # Fine-tune C around 0.1\n",
        "    {\"C\": 0.05, \"penalty\": \"l1\", \"solver\": \"liblinear\"},\n",
        "    {\"C\": 0.08, \"penalty\": \"l1\", \"solver\": \"liblinear\"},\n",
        "    {\"C\": 0.12, \"penalty\": \"l1\", \"solver\": \"liblinear\"},\n",
        "    {\"C\": 0.15, \"penalty\": \"l1\", \"solver\": \"liblinear\"},\n",
        "    # Fine-tune C with L2\n",
        "    {\"C\": 0.05, \"penalty\": \"l2\", \"solver\": \"liblinear\"},\n",
        "    {\"C\": 0.08, \"penalty\": \"l2\", \"solver\": \"liblinear\"},\n",
        "    # Try elastic net (l1_ratio blends L1 and L2)\n",
        "    {\"C\": 0.1, \"penalty\": \"elasticnet\", \"solver\": \"saga\", \"l1_ratio\": 0.5},\n",
        "    {\"C\": 0.1, \"penalty\": \"elasticnet\", \"solver\": \"saga\", \"l1_ratio\": 0.7},\n",
        "]\n",
        "\n",
        "for cfg in lr_configs:\n",
        "    run_name = f\"LR_TUNED_C{cfg['C']}_{cfg['penalty']}\"\n",
        "    if 'l1_ratio' in cfg:\n",
        "        run_name += f\"_r{cfg['l1_ratio']}\"\n",
        "\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        if cfg['penalty'] == 'elasticnet':\n",
        "            clf = LogisticRegression(C=cfg['C'], penalty=cfg['penalty'], solver=cfg['solver'],\n",
        "                                     l1_ratio=cfg['l1_ratio'], max_iter=2000, random_state=42)\n",
        "        else:\n",
        "            clf = LogisticRegression(C=cfg['C'], penalty=cfg['penalty'], solver=cfg['solver'],\n",
        "                                     max_iter=1000, random_state=42)\n",
        "\n",
        "        pipe = Pipeline([(\"prep\", preprocess_scaled), (\"clf\", clf)])\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "        rocauc = roc_auc_score(y_test, y_prob)\n",
        "        brier = brier_score_loss(y_test, y_prob)\n",
        "\n",
        "        mlflow.log_metric(\"test_accuracy\", acc)\n",
        "        mlflow.log_metric(\"test_precision\", prec)\n",
        "        mlflow.log_metric(\"test_recall\", rec)\n",
        "        mlflow.log_metric(\"test_f1\", f1)\n",
        "        mlflow.log_metric(\"roc_auc\", rocauc)\n",
        "        mlflow.log_metric(\"brier_score\", brier)\n",
        "        mlflow.log_param(\"model_type\", \"LogisticRegression_Tuned\")\n",
        "        for k, v in cfg.items():\n",
        "            mlflow.log_param(k, v)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "        log_cm(cm, f\"{run_name}_cm.png\")\n",
        "        log_curves(y_test, y_prob, f\"{run_name}_\")\n",
        "\n",
        "        lr_tuned_runs.append({\"run_name\": run_name, \"pipe\": pipe, \"f1\": f1, \"roc_auc\": rocauc, \"brier\": brier, \"config\": cfg})\n",
        "        print(f\"  {run_name}: AUC={rocauc:.4f}, Acc={acc:.4f}, F1={f1:.4f}, Brier={brier:.4f}\")\n",
        "\n",
        "print(f\"\\nâœ… Logistic Regression Fine-Tuning: {len(lr_tuned_runs)} runs completed\")\n",
        "\n",
        "# ===================================================================================\n",
        "# 3) SVM FINE-TUNING (5 runs)\n",
        "# Best was: linear kernel, C=0.1\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"3) SVM FINE-TUNING (5 runs)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "svm_tuned_runs = []\n",
        "\n",
        "svm_configs = [\n",
        "    {\"kernel\": \"linear\", \"C\": 0.05},\n",
        "    {\"kernel\": \"linear\", \"C\": 0.08},\n",
        "    {\"kernel\": \"linear\", \"C\": 0.15},\n",
        "    {\"kernel\": \"linear\", \"C\": 0.2},\n",
        "    {\"kernel\": \"linear\", \"C\": 0.5},\n",
        "]\n",
        "\n",
        "for cfg in svm_configs:\n",
        "    run_name = f\"SVM_TUNED_{cfg['kernel']}_C{cfg['C']}\"\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        clf = SVC(kernel=cfg['kernel'], C=cfg['C'], probability=True, random_state=42)\n",
        "        pipe = Pipeline([(\"prep\", preprocess_scaled), (\"clf\", clf)])\n",
        "        pipe.fit(X_train, y_train)\n",
        "        y_pred = pipe.predict(X_test)\n",
        "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "        rocauc = roc_auc_score(y_test, y_prob)\n",
        "        brier = brier_score_loss(y_test, y_prob)\n",
        "\n",
        "        mlflow.log_metric(\"test_accuracy\", acc)\n",
        "        mlflow.log_metric(\"test_precision\", prec)\n",
        "        mlflow.log_metric(\"test_recall\", rec)\n",
        "        mlflow.log_metric(\"test_f1\", f1)\n",
        "        mlflow.log_metric(\"roc_auc\", rocauc)\n",
        "        mlflow.log_metric(\"brier_score\", brier)\n",
        "        mlflow.log_param(\"model_type\", \"SVM_Tuned\")\n",
        "        for k, v in cfg.items():\n",
        "            mlflow.log_param(k, v)\n",
        "\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "        log_cm(cm, f\"{run_name}_cm.png\")\n",
        "        log_curves(y_test, y_prob, f\"{run_name}_\")\n",
        "\n",
        "        svm_tuned_runs.append({\"run_name\": run_name, \"pipe\": pipe, \"f1\": f1, \"roc_auc\": rocauc, \"brier\": brier, \"config\": cfg})\n",
        "        print(f\"  {run_name}: AUC={rocauc:.4f}, Acc={acc:.4f}, F1={f1:.4f}, Brier={brier:.4f}\")\n",
        "\n",
        "print(f\"\\nâœ… SVM Fine-Tuning: {len(svm_tuned_runs)} runs completed\")\n",
        "\n",
        "# ===================================================================================\n",
        "# TUNING SUMMARY\n",
        "# ===================================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINE-TUNING SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_tuned = xgb_tuned_runs + lr_tuned_runs + svm_tuned_runs\n",
        "tuned_df = pd.DataFrame(all_tuned).sort_values(by=\"roc_auc\", ascending=False)\n",
        "\n",
        "print(f\"\\nTotal tuned runs: {len(all_tuned)}\")\n",
        "print(f\"\\nTop 10 Tuned Models by ROC-AUC:\")\n",
        "print(tuned_df[[\"run_name\", \"roc_auc\", \"f1\", \"brier\"]].head(10).to_string(index=False))\n",
        "\n",
        "best_tuned = tuned_df.iloc[0]\n",
        "print(f\"\\nğŸ† BEST TUNED MODEL: {best_tuned['run_name']}\")\n",
        "print(f\"   ROC-AUC: {best_tuned['roc_auc']:.4f}\")\n",
        "print(f\"   F1: {best_tuned['f1']:.4f}\")\n",
        "print(f\"   Brier: {best_tuned['brier']:.4f}\")\n",
        "print(f\"   Config: {best_tuned['config']}\")\n",
        "\n",
        "# Compare to original best\n",
        "print(f\"\\nğŸ“Š IMPROVEMENT CHECK:\")\n",
        "print(f\"   Original best (XGB_n100_lr0.1_d4): ROC-AUC = 0.7168\")\n",
        "print(f\"   New best ({best_tuned['run_name']}): ROC-AUC = {best_tuned['roc_auc']:.4f}\")\n",
        "improvement = (best_tuned['roc_auc'] - 0.7168) * 100\n",
        "print(f\"   Change: {improvement:+.2f}% points\")\n",
        "\n",
        "# Save best tuned model\n",
        "import pickle\n",
        "with open('ufc_fight_predictor_tuned.pkl', 'wb') as f:\n",
        "    pickle.dump(best_tuned['pipe'], f)\n",
        "print(f\"\\nâœ… Best tuned model saved as: ufc_fight_predictor_tuned.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypD53eaMYoP_",
        "outputId": "375592b0-5ad7-442f-c478-3f46c03eea7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "HYPERPARAMETER FINE-TUNING - PHASE 2\n",
            "Based on best initial results: XGBoost & Logistic Regression\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "1) XGBOOST FINE-TUNING (12 runs)\n",
            "============================================================\n",
            "  XGB_TUNED_n100_lr0.1_d3_a0_l1_ss1.0: AUC=0.7132, Acc=0.6554, F1=0.6605, Brier=0.2161\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d3_a0_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/91a168ef9be74cacb67f1725ee3d5a8b\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.1_d5_a0_l1_ss1.0: AUC=0.7085, Acc=0.6615, F1=0.6626, Brier=0.2179\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d5_a0_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/99cd9389c4354411b440c12d86d3d7e0\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n75_lr0.1_d4_a0_l1_ss1.0: AUC=0.7171, Acc=0.6615, F1=0.6644, Brier=0.2151\n",
            "ğŸƒ View run XGB_TUNED_n75_lr0.1_d4_a0_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/dd92d36ed7114f298e85877f3cedfd18\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n150_lr0.1_d4_a0_l1_ss1.0: AUC=0.7110, Acc=0.6642, F1=0.6658, Brier=0.2174\n",
            "ğŸƒ View run XGB_TUNED_n150_lr0.1_d4_a0_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/f35cb5c2a51d4cf79c1bf3dedf67a1e3\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.08_d4_a0_l1_ss1.0: AUC=0.7161, Acc=0.6514, F1=0.6560, Brier=0.2154\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.08_d4_a0_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/9029268a14614c319b31e2003e93a92e\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.12_d4_a0_l1_ss1.0: AUC=0.7055, Acc=0.6568, F1=0.6622, Brier=0.2184\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.12_d4_a0_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/d41d0b92bb7742b1a389f02f88bb2abd\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0.1_l1_ss1.0: AUC=0.7171, Acc=0.6649, F1=0.6671, Brier=0.2151\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d4_a0.1_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/17cd17c8ba594299af37720fd9cbd56b\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0.5_l1_ss1.0: AUC=0.7163, Acc=0.6682, F1=0.6711, Brier=0.2151\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d4_a0.5_l1_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/0b3edf250735498980f3d70d4fc0ef30\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0_l2_ss1.0: AUC=0.7139, Acc=0.6588, F1=0.6608, Brier=0.2157\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d4_a0_l2_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/0ca9e6ec6ef84cf28883e50db52987b0\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0_l5_ss1.0: AUC=0.7193, Acc=0.6581, F1=0.6599, Brier=0.2142\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d4_a0_l5_ss1.0 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/796981a29c2d4dcc9f39ff9fee491dce\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0_l1_ss0.8: AUC=0.7087, Acc=0.6426, F1=0.6433, Brier=0.2173\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d4_a0_l1_ss0.8 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/8efc3dd18e694482ab660cd8362c1fe5\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0_l1_ss0.8: AUC=0.7121, Acc=0.6568, F1=0.6604, Brier=0.2163\n",
            "ğŸƒ View run XGB_TUNED_n100_lr0.1_d4_a0_l1_ss0.8 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/83be12e7646a4decb591f69bbeea930d\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "âœ… XGBoost Fine-Tuning: 12 runs completed\n",
            "\n",
            "============================================================\n",
            "2) LOGISTIC REGRESSION FINE-TUNING (8 runs)\n",
            "============================================================\n",
            "  LR_TUNED_C0.05_l1: AUC=0.7107, Acc=0.6507, F1=0.6509, Brier=0.2168\n",
            "ğŸƒ View run LR_TUNED_C0.05_l1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/0a81f01124fc4efb87f9a2bc8a0fdc98\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_TUNED_C0.08_l1: AUC=0.7134, Acc=0.6527, F1=0.6522, Brier=0.2159\n",
            "ğŸƒ View run LR_TUNED_C0.08_l1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/887c7ff3545f4fc299f0bd269be6774a\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_TUNED_C0.12_l1: AUC=0.7137, Acc=0.6514, F1=0.6518, Brier=0.2157\n",
            "ğŸƒ View run LR_TUNED_C0.12_l1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/9db9567939f548bd9105af48d9a29033\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_TUNED_C0.15_l1: AUC=0.7138, Acc=0.6534, F1=0.6555, Brier=0.2157\n",
            "ğŸƒ View run LR_TUNED_C0.15_l1 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/97c73cc2043a43719566addbac9c730d\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_TUNED_C0.05_l2: AUC=0.7095, Acc=0.6588, F1=0.6604, Brier=0.2171\n",
            "ğŸƒ View run LR_TUNED_C0.05_l2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/e039b071ca264081aaab9d557725794e\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_TUNED_C0.08_l2: AUC=0.7095, Acc=0.6622, F1=0.6626, Brier=0.2171\n",
            "ğŸƒ View run LR_TUNED_C0.08_l2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/6467bb72fff0461c9f7c888ff23dd50f\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_TUNED_C0.1_elasticnet_r0.5: AUC=0.7129, Acc=0.6547, F1=0.6559, Brier=0.2161\n",
            "ğŸƒ View run LR_TUNED_C0.1_elasticnet_r0.5 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/60382e3edaaa40d18254c513c95b4f42\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  LR_TUNED_C0.1_elasticnet_r0.7: AUC=0.7135, Acc=0.6541, F1=0.6555, Brier=0.2159\n",
            "ğŸƒ View run LR_TUNED_C0.1_elasticnet_r0.7 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/5f9fa394d9eb41da9534fa6d0d908f58\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "âœ… Logistic Regression Fine-Tuning: 8 runs completed\n",
            "\n",
            "============================================================\n",
            "3) SVM FINE-TUNING (5 runs)\n",
            "============================================================\n",
            "  SVM_TUNED_linear_C0.05: AUC=0.7105, Acc=0.6615, F1=0.6617, Brier=0.2171\n",
            "ğŸƒ View run SVM_TUNED_linear_C0.05 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/8272f73a8b264a1f8e7128a20ecf24b4\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  SVM_TUNED_linear_C0.08: AUC=0.7089, Acc=0.6642, F1=0.6644, Brier=0.2176\n",
            "ğŸƒ View run SVM_TUNED_linear_C0.08 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/904e0c7652bb4b1b90b6fc0dd2bddb29\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  SVM_TUNED_linear_C0.15: AUC=0.7052, Acc=0.6608, F1=0.6635, Brier=0.2186\n",
            "ğŸƒ View run SVM_TUNED_linear_C0.15 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/4d896a6910044374996684cd7b6fff0f\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  SVM_TUNED_linear_C0.2: AUC=0.7043, Acc=0.6554, F1=0.6586, Brier=0.2189\n",
            "ğŸƒ View run SVM_TUNED_linear_C0.2 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/80436dd2db14496a9e06e2faa7ee55c4\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "  SVM_TUNED_linear_C0.5: AUC=0.6965, Acc=0.6493, F1=0.6533, Brier=0.2213\n",
            "ğŸƒ View run SVM_TUNED_linear_C0.5 at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585/runs/d4d28f2200104a9bad7b5b73054a78fe\n",
            "ğŸ§ª View experiment at: https://dbc-4725f828-1619.cloud.databricks.com/ml/experiments/242438794216585\n",
            "\n",
            "âœ… SVM Fine-Tuning: 5 runs completed\n",
            "\n",
            "============================================================\n",
            "FINE-TUNING SUMMARY\n",
            "============================================================\n",
            "\n",
            "Total tuned runs: 25\n",
            "\n",
            "Top 10 Tuned Models by ROC-AUC:\n",
            "                             run_name  roc_auc       f1    brier\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0_l5_ss1.0 0.719302 0.659946 0.214206\n",
            "XGB_TUNED_n100_lr0.1_d4_a0.1_l1_ss1.0 0.717093 0.667114 0.215122\n",
            "   XGB_TUNED_n75_lr0.1_d4_a0_l1_ss1.0 0.717075 0.664434 0.215140\n",
            "XGB_TUNED_n100_lr0.1_d4_a0.5_l1_ss1.0 0.716255 0.671132 0.215101\n",
            " XGB_TUNED_n100_lr0.08_d4_a0_l1_ss1.0 0.716135 0.656000 0.215362\n",
            "  XGB_TUNED_n100_lr0.1_d4_a0_l2_ss1.0 0.713948 0.660846 0.215720\n",
            "                    LR_TUNED_C0.15_l1 0.713815 0.655473 0.215731\n",
            "                    LR_TUNED_C0.12_l1 0.713711 0.651822 0.215703\n",
            "        LR_TUNED_C0.1_elasticnet_r0.7 0.713464 0.655451 0.215872\n",
            "                    LR_TUNED_C0.08_l1 0.713353 0.652233 0.215852\n",
            "\n",
            "ğŸ† BEST TUNED MODEL: XGB_TUNED_n100_lr0.1_d4_a0_l5_ss1.0\n",
            "   ROC-AUC: 0.7193\n",
            "   F1: 0.6599\n",
            "   Brier: 0.2142\n",
            "   Config: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 4, 'reg_alpha': 0, 'reg_lambda': 5, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
            "\n",
            "ğŸ“Š IMPROVEMENT CHECK:\n",
            "   Original best (XGB_n100_lr0.1_d4): ROC-AUC = 0.7168\n",
            "   New best (XGB_TUNED_n100_lr0.1_d4_a0_l5_ss1.0): ROC-AUC = 0.7193\n",
            "   Change: +0.25% points\n",
            "\n",
            "âœ… Best tuned model saved as: ufc_fight_predictor_tuned.pkl\n"
          ]
        }
      ]
    }
  ]
}